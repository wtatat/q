# Решение задачи предсказания оценок книг

## Описание

Baseline-решение задачи регрессии для предсказания оценок книг на основе истории взаимодействий пользователей.

## Структура проекта

```
.
├── train.py                 # Основной скрипт обучения и предсказания
├── submission.csv           # Файл с предсказаниями для тестовой выборки
├── requirements.txt         # Зависимости проекта
├── data/
│   └── raw/                 # Исходные данные
│       ├── train.csv
│       ├── test.csv
│       ├── books.csv
│       ├── users.csv
│       ├── book_genres.csv
│       ├── genres.csv
│       └── book_descriptions.csv
└── baseline (2).ipynb       # Исходный notebook с бейзлайном
```

## Основные признаки

1. **Агрегированные признаки**:
   - Средняя оценка пользователя
   - Количество оценок пользователя
   - Средняя оценка книги
   - Количество оценок книги
   - Средняя оценка автора

2. **Метаданные**:
   - Пол и возраст пользователя
   - Автор, год публикации, язык, издательство книги
   - Количество жанров книги

3. **Текстовые признаки** (не использованы из-за отсутствия описаний):
   - TF-IDF из описаний книг
   - BERT эмбеддинги описаний

## Модель

- **Алгоритм**: LightGBM (Gradient Boosting)
- **Метрики валидации** (после улучшений):
  - RMSE: 2.8071
  - MAE: 2.0702
  - **Validation Score: 0.756** (целевой: 0.772)
- **Временное разделение**: 85% для обучения, 15% для валидации
- **Признаков**: 39 (расширенные агрегации, жанры, взаимодействия)

## Запуск

### Установка зависимостей

```bash
pip install -r requirements.txt
```

### Полный pipeline

```bash
python train.py --step all
```

### Отдельные этапы

```bash
# Подготовка данных
python train.py --step prepare

# Обучение модели
python train.py --step train

# Генерация предсказаний
python train.py --step predict

# Валидация формата
python train.py --step validate
```

## Результаты

Файл `submission.csv` содержит предсказания для 2894 пар (user_id, book_id) из тестовой выборки.

## Особенности реализации

- Корректное хронологическое разделение данных (без утечек из будущего)
- Агрегированные признаки вычисляются только на обучающих данных
- Обработка пропущенных значений
- Оптимизация использования памяти
- Категориальные признаки обрабатываются нативно в LightGBM
